<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="sha256-AbA177XfpSnFEvgpYu1jMygiLabzPCJCRIBtR5jGc0k=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.13.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="A start-up introduction to the basic matrix analysis in numerical linear algebra.">
<meta property="og:type" content="article">
<meta property="og:title" content="Linear Algebra Done Left - Vanilla Matrix Analysis">
<meta property="og:url" content="http://example.com/2022/11/05/NumericalLA-VanillaMA/index.html">
<meta property="og:site_name" content="&quot;The World&quot; of CLV">
<meta property="og:description" content="A start-up introduction to the basic matrix analysis in numerical linear algebra.">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-11-04T16:07:44.000Z">
<meta property="article:modified_time" content="2023-05-02T15:44:14.065Z">
<meta property="article:author" content="CLV">
<meta property="article:tag" content="Numerical Method">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/2022/11/05/NumericalLA-VanillaMA/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2022/11/05/NumericalLA-VanillaMA/","path":"2022/11/05/NumericalLA-VanillaMA/","title":"Linear Algebra Done Left - Vanilla Matrix Analysis"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Linear Algebra Done Left - Vanilla Matrix Analysis | "The World" of CLV</title>
  






  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">"The World" of CLV</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-guestbook"><a href="/guestbook/" rel="section"><i class="comment fa-fw"></i>guestbook</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="user fa-fw"></i>About</a></li><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="home fa-fw"></i>Home</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%85%B3%E4%BA%8E%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%80%E8%BF%91%E5%BC%80%E4%BA%86%E8%BF%99%E4%B8%AA%E5%9D%91%EF%BC%9A"><span class="nav-number">1.</span> <span class="nav-text">关于为什么最近开了这个坑：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%99%E6%98%AF%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%89%A9%E4%B8%8B%E7%9A%84%E8%BF%98%E9%9C%80%E8%A6%81%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%86%85%E5%AE%B9%E3%80%82-%E8%BF%99%E4%B8%AA%E7%B3%BB%E5%88%97%E5%8D%9A%E5%AE%A2%E4%BC%9A%E7%94%A8%E6%9D%A5%E8%AE%B0%E5%BD%95%E6%95%B0%E5%80%BC%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E7%90%86%E8%AE%BA%E4%B8%8E%E5%BA%94%E7%94%A8%E3%80%82"><span class="nav-number">1.0.1.</span> <span class="nav-text">这是线性代数剩下的还需要学习的内容。 这个系列博客会用来记录数值线性代数中的一些理论与应用。</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#text-2-%E7%9F%A9%E9%98%B5%E5%88%86%E6%9E%90%E5%9F%BA%E7%A1%80"><span class="nav-number">2.</span> <span class="nav-text">$\text{2. 矩阵分析基础}$</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#text-2-1-First-Things-First"><span class="nav-number">2.1.</span> <span class="nav-text">$\text{2.1. First Things First}$</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#text-Sherman-Morrison-Woodbury%E5%85%AC%E5%BC%8F"><span class="nav-number">2.1.0.1.</span> <span class="nav-text">$\text{Sherman-Morrison-Woodbury公式}$</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#text-%E7%9F%A9%E9%98%B5%E5%92%8C%E5%90%91%E9%87%8F%E8%8C%83%E6%95%B0"><span class="nav-number">2.1.0.2.</span> <span class="nav-text">$\text{矩阵和向量范数}$</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#text-%E7%9F%A9%E9%98%B5%E7%9A%842-%E8%8C%83%E6%95%B0"><span class="nav-number">2.1.0.3.</span> <span class="nav-text">$\text{矩阵的2-范数}$</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#text-%E9%80%86%E7%9F%A9%E9%98%B5%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AF%AF%E5%B7%AE%E4%BC%B0%E8%AE%A1"><span class="nav-number">2.1.0.4.</span> <span class="nav-text">$\text{逆矩阵的一些误差估计}$</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#text-The-Eckhart-Young-Theorem"><span class="nav-number">2.1.0.5.</span> <span class="nav-text">$\text{The Eckhart-Young Theorem}$</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#text-2-2-%E5%AD%90%E7%A9%BA%E9%97%B4%E5%BA%A6%E9%87%8F"><span class="nav-number">2.2.</span> <span class="nav-text">$\text{2.2. 子空间度量}$</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#text-2-2-1-%E6%AD%A3%E4%BA%A4%E6%8A%95%E5%BD%B1"><span class="nav-number">2.2.1.</span> <span class="nav-text">$\text{2.2.1. 正交投影}$</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#text-2-2-2-%E5%AD%90%E7%A9%BA%E9%97%B4%E7%9A%84%E8%B7%9D%E7%A6%BB"><span class="nav-number">2.2.2.</span> <span class="nav-text">$\text{2.2.2. 子空间的距离}$</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#text-2-2-3-CS%E5%88%86%E8%A7%A3"><span class="nav-number">2.2.3.</span> <span class="nav-text">$\text{2.2.3. CS分解}$</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#text-2-3-%E7%BA%BF%E6%80%A7%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%95%8F%E6%84%9F%E6%80%A7"><span class="nav-number">2.3.</span> <span class="nav-text">$\text{2.3. 线性系统的敏感性}$</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#text-2-3-1-%E6%9D%A1%E4%BB%B6%E6%95%B0"><span class="nav-number">2.3.1.</span> <span class="nav-text">$\text{2.3.1. 条件数}$</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#text-2-4-%E6%9C%89%E9%99%90%E7%B2%BE%E5%BA%A6%E7%9A%84%E8%AE%A1%E7%AE%97"><span class="nav-number">2.4.</span> <span class="nav-text">$\text{2.4. 有限精度的计算}$</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#text-2-4-1-%E8%88%8D%E5%85%A5%E8%AF%AF%E5%B7%AE"><span class="nav-number">2.4.1.</span> <span class="nav-text">$\text{2.4.1. 舍入误差}$</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#text-2-4-2-%E6%B5%AE%E7%82%B9%E6%95%B0%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"><span class="nav-number">2.4.2.</span> <span class="nav-text">$\text{2.4.2. 浮点数注意事项}$</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E9%A1%BA%E5%BA%8F%E5%BE%88%E9%87%8D%E8%A6%81"><span class="nav-number">2.4.2.1.</span> <span class="nav-text">计算顺序很重要</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%80%BC%E8%BF%91%E7%B2%BE%E5%BA%A6%E5%B0%8F%E4%B8%8D%E4%B8%80%E5%AE%9A%E6%98%AF%E7%9C%9F%E7%9A%84%E5%B0%8F"><span class="nav-number">2.4.2.2.</span> <span class="nav-text">逼近精度小不一定是真的小</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#text-2-4-3-%E5%BA%94%E7%94%A8%EF%BC%9A%E5%AD%98%E5%82%A8%E7%9F%A9%E9%98%B5"><span class="nav-number">2.4.3.</span> <span class="nav-text">$\text{2.4.3. 应用：存储矩阵}$</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#text-2-4-4-%E5%89%8D%E5%90%91%E5%92%8C%E5%90%8E%E5%90%91%E8%AF%AF%E5%B7%AE%E5%88%86%E6%9E%90"><span class="nav-number">2.4.4.</span> <span class="nav-text">$\text{2.4.4. 前向和后向误差分析}$</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#text-2-4-5-%E5%88%86%E6%9E%90%E7%90%86%E6%83%B3%E7%9A%84%E8%A7%A3%E6%96%B9%E7%A8%8B%E7%BB%84"><span class="nav-number">2.4.5.</span> <span class="nav-text">$\text{2.4.5. 分析理想的解方程组}$</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#text-Fin"><span class="nav-number">3.</span> <span class="nav-text">$\text{Fin.}$</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">CLV</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">38</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/CreeperLordVader-Iclucia-Ashina" class="github-corner" title="Fork me on GitHub!" aria-label="Fork me on GitHub!" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/11/05/NumericalLA-VanillaMA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="CLV">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content=""The World" of CLV">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Linear Algebra Done Left - Vanilla Matrix Analysis | "The World" of CLV">
      <meta itemprop="description" content="A start-up introduction to the basic matrix analysis in numerical linear algebra.">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Linear Algebra Done Left - Vanilla Matrix Analysis
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-11-05 00:07:44" itemprop="dateCreated datePublished" datetime="2022-11-05T00:07:44+08:00">2022-11-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-05-02 23:44:14" itemprop="dateModified" datetime="2023-05-02T23:44:14+08:00">2023-05-02</time>
    </span>

  
</div>

            <div class="post-description">A start-up introduction to the basic matrix analysis in numerical linear algebra.</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="关于为什么最近开了这个坑："><a href="#关于为什么最近开了这个坑：" class="headerlink" title="关于为什么最近开了这个坑："></a>关于为什么最近开了这个坑：</h1><p>因为发现学校里教的线代毕竟是比较理论的东西，教的计算方法写成程序拿来实战百分之百是会被残酷的数据碾爆的。毕竟现实中的矩阵一多半是大而优雅或者小而丑陋<del>或者大而丑陋</del>，哪个都不是大一线代课上讲的一个小小的高斯消元就能解决的。<del>要么时间爆炸，要么数值误差爆炸，至少有一个适合你。</del></p>
<p>另一方面，计算机图形学中，无论是物理模拟还是几何处理都不可避免地要与大规模的矩阵打交道，因此很有必要建立自己的数值线性代数库，学习矩阵计算的方法。</p>
<h3 id="这是线性代数剩下的还需要学习的内容。-这个系列博客会用来记录数值线性代数中的一些理论与应用。"><a href="#这是线性代数剩下的还需要学习的内容。-这个系列博客会用来记录数值线性代数中的一些理论与应用。" class="headerlink" title="这是线性代数剩下的还需要学习的内容。 这个系列博客会用来记录数值线性代数中的一些理论与应用。"></a>这是线性代数剩下的还需要学习的内容。 这个系列博客会用来记录数值线性代数中的一些理论与应用。</h3><span id="more"></span>

<p><del>没错你已经发现了这不是讲线性代数的而是讲数值线性代数的</del></p>
<p>关于数值线代在网上并没有找到什么特别猛料的网课（也可能是我手段不足？），不过$\text{MIT}$的$\text{Strang}$老爷子新开的”数据分析中的矩阵方法”还是非常不错，就是太简单了，属于是讲给宝宝的矩阵计算入门<del>特别适合下饭或者赶路</del>。这一次我们参考数值线代的圣经 <em>Matrix Computation</em> 来学习。</p>
<h1 id="text-2-矩阵分析基础"><a href="#text-2-矩阵分析基础" class="headerlink" title="$\text{2. 矩阵分析基础}$"></a>$\text{2. 矩阵分析基础}$</h1><p>很多东西在别的地方都有提过，无论是数学物理方法还是数值分析都有讲过向量范数，矩阵范数等等的概念，这些概念在此当然不会再全部扯一遍<del>当然在那些地方我也不会再扯一遍</del>。这里只是过一些简单的结论和话题。这一章的主要目的应当还是掌握必备的误差估计的知识。</p>
<h2 id="text-2-1-First-Things-First"><a href="#text-2-1-First-Things-First" class="headerlink" title="$\text{2.1. First Things First}$"></a>$\text{2.1. First Things First}$</h2><p>很多线性代数里老生常谈的东西这里也就不多加叙述了。但是有些东西，学院派的线性代数可能不怎么管它，在数值方法里却还是有点用处的。</p>
<h4 id="text-Sherman-Morrison-Woodbury公式"><a href="#text-Sherman-Morrison-Woodbury公式" class="headerlink" title="$\text{Sherman-Morrison-Woodbury公式}$"></a>$\text{Sherman-Morrison-Woodbury公式}$</h4><p>对于可逆矩阵$A, B$来说，有$B^{-1}&#x3D;A^{-1}-B^{-1}(B-A)A^{-1}$。验证起来还是很容易的。</p>
<p>没人会蠢到用这个东西去求逆，但是如果我们用$A+UV^T$代替这里的$B$，就可以得到 $\text{Sherman-Morrison-Woodbury}$公式:</p>
<p>$$(A+UV^T)^{-1}&#x3D;A^{-1}-(A+UV^T)^{-1}UV^TA^{-1}&#x3D;A^{-1}-A^{-1}(E+UV^TA^{-1})^{-1}UV^TA^{-1}$$</p>
<p>$$&#x3D;A^{-1}-A^{-1}(U^{-1}+U^{-1}UV^TA^{-1})^{-1}V^TA^{-1}&#x3D;A^{-1}-A^{-1}(U^{-1}+V^TA^{-1})^{-1}V^TA^{-1}$$</p>
<p>$$&#x3D;A^{-1}-A^{-1}U(E_k+V^TA^{-1}U)^{-1}V^TA^{-1}$$</p>
<p>这里唯一要运用的就是矩阵乘积的逆的性质，并不难（但是我居然还想了一会儿，丢人）。</p>
<p>这个公式看起来更丑了，但是它好就好在$U,V$可以不是方阵，事实上$U,V\in \mathbb{R}^{n\times k}$就可以，而$k$可以是任意的（对于任意的$k$的情况可以由方阵情况推出）。特别的我们取$k&#x3D;1$，这时$U,V$退化为向量$u, v$。取$\alpha&#x3D;1+v^TA^{-1}u$就有</p>
<p>$$(A+uv^T)^{-1}&#x3D;A^{-1}-\frac{1}{\alpha}A^{-1}uv^TA^{-1}$$</p>
<p>这个式子被称为$\text{Sherman-Morrison}$公式，很有用，在$\text{Strang}$老爷子的课里也讲过这个东西，可以用于对矩阵的低秩扰动的求逆，后者就更加有用了。</p>
<h4 id="text-矩阵和向量范数"><a href="#text-矩阵和向量范数" class="headerlink" title="$\text{矩阵和向量范数}$"></a>$\text{矩阵和向量范数}$</h4><p>向量范数再稍微提一个性质也就是著名的赫尔德不等式：</p>
<p>$$|x^Ty|\le \parallel x \parallel_p\parallel y\parallel_q,\frac{1}{p}+\frac{1}{q}&#x3D;1 $$</p>
<p>首先说明一点，在有限维空间中，范数都是等价的，因此这里我们取各种乱七八糟的范数，数值效果可能有区别，不过至少收敛性上都是没啥问题的。但是在无穷维空间上就没那么幸运了，这些事情就需要留给<del>犯寒</del>泛函分析，这里当然就不提了。</p>
<p>$\text{Frobenius}$范数自不必多说，这里再简单回顾一下矩阵的算子范数。</p>
<p>矩阵$A$的算子范数定义为$\parallel A\parallel&#x3D;\max\limits_{\parallel x\parallel&#x3D;1}\parallel Ax\parallel$，当然，这是和选取的向量范数有关的。</p>
<p>关于算子范数有一个挺不错的性质：</p>
<p>$$\parallel AB\parallel \le \parallel A\parallel\parallel B\parallel$$</p>
<p>这对任意的矩阵$A,B$都成立，当然实际上考虑到矩阵范数作为函数，对于不同形状的矩阵是不同的，这个不等式比看起来的还是要更好，它甚至能揭示出三个完全不一样的函数的关系。</p>
<p>还有另外一种矩阵范数的定义，更宽泛：</p>
<p>$$\parallel A\parallel_{\alpha,\beta}&#x3D;\max\limits_{\parallel x\parallel_\alpha &#x3D; 1}\parallel Ax\parallel_\beta$$</p>
<h4 id="text-矩阵的2-范数"><a href="#text-矩阵的2-范数" class="headerlink" title="$\text{矩阵的2-范数}$"></a>$\text{矩阵的2-范数}$</h4><p>$\text{Thm.}$ 存在单位向量$x$使得$A^TAz&#x3D;\mu^2x$,$\mu &#x3D; \parallel A\parallel_2$</p>
<p>这个定理的证明还是得依据定义来。。。假设存在这样的$z$就一定有$\parallel Az\parallel_2&#x3D;\parallel A\parallel_2$</p>
<p>令$g(x)&#x3D;\frac{\parallel Ax\parallel_2^2}{2\parallel x\parallel_2^2}$</p>
<p>$z$最小化$g(x)$于是就可以求梯度并且令其为$0$，最终能得到</p>
<p>$$A^TAz&#x3D;(z^TA^TAz)z$$</p>
<p>比较一下就知道$\parallel Az\parallel_2&#x3D;\mu$</p>
<p>这其实揭示了一个事情:$\parallel A\parallel_2^2$是$p(\lambda)&#x3D;\det(A^TA-\lambda I)$的零点，也就是说<br>$\parallel A\parallel_2&#x3D;\sqrt{\lambda_{\max}(A^TA)}$</p>
<h4 id="text-逆矩阵的一些误差估计"><a href="#text-逆矩阵的一些误差估计" class="headerlink" title="$\text{逆矩阵的一些误差估计}$"></a>$\text{逆矩阵的一些误差估计}$</h4><p>$\text{Lemma.}$ 设$F\in \mathbb{R}^{n\times n},\parallel F\parallel_p &lt; 1$，则$I-F$可逆，且有</p>
<p>$$\parallel (I-F)^{-1}\parallel_p \le \frac{1}{1-\parallel F\parallel}$$</p>
<p>可逆性的证明是经典的习题，因为我们能发现$I-F$是一个对角占优矩阵，对角占优矩阵是可逆的。不过这里还有另一个结论：</p>
<p>$$(I-F)^{-1}&#x3D;\sum\limits_{k&#x3D;0}^\infty F^k$$</p>
<p>这么写当然是OK的，因为$F$的范数小于$1$，这一定是收敛的。</p>
<p>两侧取范数，右边变成无穷等比数列求和，就得到了范数不等式。</p>
<p>这个引理表明了另一个事情：</p>
<p>$$\parallel (I-F)^{-1}-I\parallel_p \le \frac{\parallel F\parallel_p}{1-\parallel F \parallel_p}$$</p>
<p>考虑$\parallel F\parallel_p \sim O(\epsilon)$且$\epsilon \ll 1$，这意味着，如果我们对单位矩阵进行$O(\epsilon)$的扰动，其逆的变化也是$O(\epsilon)$的。</p>
<p>有了这个引理就能得到下面的定理:</p>
<p>$\text{Thm.}$ 若$A$可逆，且$r&#x3D;\parallel A^{-1}E\parallel_p &lt; 1$,那么$A+E$可逆且</p>
<p>$$(A+E)^{-1}-A^{-1}\le \frac{\parallel E\parallel_p\parallel A^{-1}\parallel_p^2}{1-r}$$</p>
<p>$\text{Proof.}$ 设$F&#x3D;-EA^{-1}$，容易验证</p>
<p>$$(A+E)^{-1}-A^{-1}&#x3D;-A^{-1}EA^{-1}(I+F)^{-1}$$</p>
<p>两侧取范数即可</p>
<h4 id="text-The-Eckhart-Young-Theorem"><a href="#text-The-Eckhart-Young-Theorem" class="headerlink" title="$\text{The Eckhart-Young Theorem}$"></a>$\text{The Eckhart-Young Theorem}$</h4><p>这个定理的前置是$\text{SVD}$，$\text{SVD}$到处都有讲，本来应该说是个很重要的概念，但是因为实在是过于普遍所以这里就不多提了。</p>
<p>所幸网上已有很多资料，读者可以自行学习。<del>这里至少应该给出个结论但是我连结论也不会给的。</del></p>
<p>这个定理在$\text{Strang}$老爷子的课里也专门讲过，但是$\text{Strang}$没有讲证明<del>实际上他那个课都不怎么讲证明</del>。这个定理是矩阵低秩近似的理论基础，还是相当重要的。</p>
<p>$\text{Thm.}$ 若$k &lt; r &#x3D; rk(A)$，令$A_k&#x3D;\sum\limits_{i&#x3D;1}^k\sigma_iu_iv_i^T$，则有</p>
<p>$$\min\limits_{rk(B)&#x3D;k}\parallel A-B\parallel_2&#x3D;\parallel A-A_k\parallel_2&#x3D;\sigma_{k+1}$$</p>
<p>当然，这里$\sigma_{k+1}$说的是奇异值，并且$\sigma$是从大往小排列的。</p>
<p>第二个等式相当容易验证的，重点是第一个。</p>
<p>首先很容易发现$A_k$的确是个秩为$k$的矩阵，我们要证明没有秩为$k$矩阵能比$A_k$<del>更懂如何逼近</del>逼近得更好，即要证明</p>
<p>$$\parallel A-B\parallel_2^2\ge \sigma_{k+1}^2$$</p>
<p>首先寻找矩阵$B$的零空间$\text{null}(B)$的一组正交基${x_1,x_2,…x_{n-k}}$</p>
<p>运用维数公式，我们有</p>
<p>$$\text{dim}(\text{null}(B))+\text{dim}(&lt;v_1,v_2,…,v_{k+1}&gt;)-\text{dim}(\text{null}(B)\cap &lt;v_1,v_2,…,v_{k+1}&gt;)\le n$$</p>
<p>即</p>
<p>$$n-k+k+1-\text{dim}(\text{null}(B)\cap &lt;v_1,v_2,…,v_{k+1}&gt;)\le n$$</p>
<p>即有$\text{dim}(\text{null}(B)\cap &lt;v_1,v_2,…,v_{k+1}&gt;)\ge 1$</p>
<p>这说明$S&#x3D;\text{null}(B)\cap &lt;v_1,v_2,…,v_{k+1}&gt; \neq {0}$，线性代数老师应该也提醒过这个地方绝对不能把${0}$写成空集。</p>
<p>设$z$是$S$中的单位向量，于是有</p>
<p>$$Az&#x3D;\sum\limits_{i&#x3D;1}^{k+1}u_i\sigma_i v_i^Tz &#x3D;\sum\limits_{i&#x3D;1}^{k+1}\sigma_iu_i(z^Tv_i) &#x3D;\sum\limits_{i&#x3D;1}^{k+1}\sigma_i(v_i^Tz)u_i$$</p>
<p>$$\parallel Az-Bz\parallel_2^2&#x3D;\parallel Az\parallel_2^2&#x3D;\parallel \sum\limits_{i&#x3D;1}^{k+1}\sigma_i(v_i^Tz)u_i\parallel_2^2$$</p>
<p>首先由于$u_i$是单位正交基，我们可以直接把范数和求和交换并且化简。于是</p>
<p>$$\parallel (A-B)z\parallel_2^2&#x3D;\sum\limits_{i&#x3D;1}^{k+1}\sigma_i^2(v_i^Tz)^2$$</p>
<p>其次，由于$z\in &lt;v_1,v_2,…,v_{k+1}&gt;$并且$\parallel z\parallel_2^2&#x3D;1$，而且$v_1,v_2,…,v_{k+1}$都是单位正交基，有</p>
<p>$$\parallel z\parallel_2^2&#x3D;\sum\limits_{i&#x3D;1}^{k+1}(v_i^Tz)^2&#x3D;1$$</p>
<p>所以说$\parallel (A-B)z\parallel_2^2&#x3D;\sum\limits_{i&#x3D;1}^{k+1}\sigma_i^2(v_i^Tz)^2$是$\sigma_1^2,\sigma_2^2,…\sigma_{k+1}^2$的凸组合，它肯定比最小的那一个即$\sigma_{k+1}^2$要大，由于对任意满足条件的$\parallel (A-B)z\parallel_2^2$都成立，我们取其上确界应当还是成立的，由于这个上确界一定不比$\parallel A-B\parallel_2^2$大（因为$z$取不到全空间）。就有</p>
<p>$$\parallel A-B\parallel_2^2\ge \sigma_{k+1}^2$$</p>
<h2 id="text-2-2-子空间度量"><a href="#text-2-2-子空间度量" class="headerlink" title="$\text{2.2. 子空间度量}$"></a>$\text{2.2. 子空间度量}$</h2><p>很多时候我们希望能够衡量两个子空间有多“接近”，或者说两个子空间有多少“重合”。这个时候考虑子空间的正交基就是非常好的，因为正交基拥有很好的运算性质。</p>
<h3 id="text-2-2-1-正交投影"><a href="#text-2-2-1-正交投影" class="headerlink" title="$\text{2.2.1. 正交投影}$"></a>$\text{2.2.1. 正交投影}$</h3><p>其实要说吧，这个概念线代课上也讲过，不过这里还是重新提一下，至少给出一些重要结论，尤其是一些矩阵结论<del>坦白说这一块儿我是没学好的最后还是滚去问了线代老师</del>。</p>
<p>正交投影表示把一个向量投影到子空间上，所谓投影也就是说将向量分解为在子空间和其正交补空间中的两部分然后取前者。正交投影其作为算子肯定有其对应的方阵，依此定义:</p>
<p>如果$P\in \mathbb{R}^{n\times n}$满足$\text{ran}(P)&#x3D;S$,且$P^2&#x3D;P,P^T&#x3D;P$称其为子空间$S$上的正交投影。</p>
<p>这里$\text{ran}$就是把矩阵作为线性映射的像空间，或者说矩阵的列空间。</p>
<p>$\text{ran}(P)$是列空间。本来投影算子的定义其实可以没有对称性的，但是这里有。这一点。。。挺迷的</p>
<p>一个重要的结论是，如果子空间$S$的一组单位正交基拼成的矩阵是$V&#x3D;[v_1|v_2|…|v_k]$，那么$P$上的正交投影矩阵$P&#x3D;VV^T$。</p>
<p>这个玩意儿。。。很容易验证它确实满足上面的定义。但是这个结构我不是很能用线性映射去理解它。。。</p>
<p>在此特别感谢我的线性代数老师，拜托他解读了一下其中的线性映射理解，写得非常清晰。</p>
<p>有了这些东西，再结合$\text{SVD}$，我们就能够对子空间进行各种拆解。</p>
<p>考虑奇异值分解$A&#x3D;U\Sigma V^T$，设$\text{rank}(A)&#x3D;k$，将$U$写为$[U_k|\tilde{U_k}]$，其中$U_k&#x3D;[u_1,u_2,…,u_k]$，用同样的方法将$V$写为$[V_k|\tilde{V_k}]$</p>
<p>于是我们就知道，$\text{ran}(A)&#x3D;\text{ran}(U\Sigma V^T)&#x3D;\text{ran}(\Sigma V^T)&#x3D;\text{ran}(V\Sigma^T)&#x3D;\text{ran}(V_k)$。第二个等号成立是因为$U$是满秩矩阵。</p>
<p>这说明$V_k$是$\text{ran}(A)$的一组单位正交基，由于由上面的结论我们就可以把各种正交投影矩阵写出来。</p>
<p>例如，假设做奇异值分解后$A&#x3D;U\Sigma V^T$，设$\text{rank(A)}&#x3D;k$，且$U&#x3D;[\tilde{U_k}|\tilde{U_{n-k}}],V&#x3D;[\tilde{V_k}|\tilde{V_{n-k}}]$，我们就能根据上面的结论写出$\text{null}(A),\text{ran}(A)$等等的正交投影矩阵。</p>
<h3 id="text-2-2-2-子空间的距离"><a href="#text-2-2-2-子空间的距离" class="headerlink" title="$\text{2.2.2. 子空间的距离}$"></a>$\text{2.2.2. 子空间的距离}$</h3><p>其实距离好定义，就是两个子空间(维度相同)中点的距离的最小值。我们同样可以用矩阵来给出这个度量。</p>
<p>$\text{Thm.}$设$W&#x3D;[W_1|W_2],Z&#x3D;[Z_1|Z_2]$都是$n\times n$方阵，$W_1,Z_1\in \mathbb{R}^{n\times k}$，若$S_1&#x3D;\text{ran}(W_1),S_2&#x3D;\text{ran}(Z_1)$，则有</p>
<p>$$\text{dist}(S_1,S_2)&#x3D;\parallel W^TZ_2\parallel_2&#x3D;\parallel Z_1^TW_2\parallel_2$$</p>
<p>证明主要运用分块矩阵，关键是发现$\text{dist}(S_1,S_2)&#x3D;\parallel W_1W_1^T-Z_1Z_1^T\parallel_2$</p>
<h3 id="text-2-2-3-CS分解"><a href="#text-2-2-3-CS分解" class="headerlink" title="$\text{2.2.3. CS分解}$"></a>$\text{2.2.3. CS分解}$</h3><p>一个简化版的结论是:</p>
<p>$\text{Thm.}$ 考虑矩阵</p>
<p>$$Q&#x3D;\begin{bmatrix} Q_1\Q_2\end{bmatrix}$$</p>
<p>且$Q_1\in \mathbb{R}^{m_1\times n},Q_2\in \mathbb{R}^{m_2\times n}$</p>
<p>如果$Q$的列向量正交，则存在正交矩阵$U_1,U_2,V$使得</p>
<p>$$\begin{bmatrix}U_1&amp;0\0&amp;U_2\end{bmatrix}\begin{bmatrix}Q_1\Q_2\end{bmatrix}V&#x3D;\begin{bmatrix}C\S\end{bmatrix}$$</p>
<p>其中$C,S$都是对角矩阵，且$C&#x3D;\text{diag}(\cos(\theta_1), … \cos(\theta_n)),S&#x3D;C&#x3D;\text{diag}(\sin(\theta_1), … \sin(\theta_n))$</p>
<p>证明方法是首先对$Q_1$做$\text{SVD}$得到$U_1,V$，然后构造$U_2$，分离出$Q_2$的一个可以同时被$V$对角化的子空间。证明涉及到很多量化的性质。</p>
<p>一般性的结论是：</p>
<p>$\text{Thm.}$若$Q&#x3D;\begin{bmatrix}Q_{11}&amp;Q_{12}\Q_{21}&amp;Q_{22}\end{bmatrix}$是正交矩阵，就可以把它写成一个很丑的但是只含$C,S,I,0$块的矩阵。。。</p>
<p>如果去看看这个形式其实能发现两个子空间的正交基确实有一定联系但是不知道有啥用。。。</p>
<h2 id="text-2-3-线性系统的敏感性"><a href="#text-2-3-线性系统的敏感性" class="headerlink" title="$\text{2.3. 线性系统的敏感性}$"></a>$\text{2.3. 线性系统的敏感性}$</h2><p>实话说。。。上面那一节真挺无聊也不知道有啥用<del>差点让我还没起步就弃坑了</del>，但是这个话题就很有用了。</p>
<p>这一节我们的研究对象就只有一个$Ax&#x3D;b,A\in \mathbb{R}^{n\times n},b\in \mathbb{R}^n$</p>
<h3 id="text-2-3-1-条件数"><a href="#text-2-3-1-条件数" class="headerlink" title="$\text{2.3.1. 条件数}$"></a>$\text{2.3.1. 条件数}$</h3><p>这其实是数值分析里讲过的话题。。。但是我很幸运地看完了那一章然后一点都不记得（</p>
<p>通过奇异值分解，我们可以写出来$A&#x3D;\sum\limits_{i&#x3D;1}^n\sigma_iu_iv_i^T$</p>
<p>于是解得$x&#x3D;\sum\limits_{i&#x3D;1}^n \frac{u_i^Tb}{\sigma_i}v_i$</p>
<p>可以发现，如果不幸的是某些$\sigma_i$极其小，那么在这些方向上对$A$或者$b$一点小扰动就会让解产生很大的偏移。</p>
<p>为了更加精细地衡量这个偏移，我们考虑一个微扰的线性系统</p>
<p>$$(A+\epsilon F)x(\epsilon) &#x3D; b+\epsilon f,x(0)&#x3D;x$$</p>
<p>假设$A$是可逆的，那么$x(\epsilon)$在原点至少一个小邻域内是可积的，而且$\epsilon$很小，我们可以在原点附近用泰勒展开来近似$x(\epsilon)$，但是要求$x(\epsilon)$的导数直接算并不是很直观，所以我们用隐函数求导会比较方便。</p>
<p>$$A\dot{x}(\epsilon)+Fx(\epsilon)+\epsilon F\dot{x}(\epsilon) &#x3D; f$$</p>
<p>代入$\epsilon &#x3D; 0$得$\dot{x}(\epsilon)&#x3D;A^{-1}(f-Fx)$</p>
<p>现在再用泰勒展开</p>
<p>$$x(\epsilon)-x&#x3D;A^{-1}(f-Fx)\epsilon+O(\epsilon^2)$$</p>
<p>为了估计误差，我们将其取范数并在两侧除以$\parallel x\parallel$，得到</p>
<p>$$\frac{\parallel x(\epsilon)-x\parallel}{\parallel x\parallel}\le \epsilon\parallel A^{-1}\parallel{\frac{\parallel f\parallel}{\parallel x\parallel}+\parallel F\parallel}+O(\epsilon^2)$$</p>
<p>对于方阵$A$，我们定义$A$的条件数为$\kappa(A)&#x3D;\parallel A\parallel\parallel A^{-1}\parallel$</p>
<p>如果$A$不可逆，我们可以顺利成章地定义$\kappa(A)&#x3D;+\infty$</p>
<p>由于$\parallel b\parallel\parallel A\parallel^{-1}\le \parallel x\parallel$，我们可以把上面的不等式里的$\parallel x\parallel$放缩掉，来把右边整理成和$A,b$的相对误差有关的不等式</p>
<p>$$\frac{\parallel x(\epsilon)-x\parallel}{\parallel x\parallel}\le \kappa(A)(\rho_A+\rho_b)+O(\epsilon^2)$$</p>
<p>其中$\rho_A&#x3D;\epsilon \frac{\parallel F\parallel}{\parallel A\parallel},\rho_A&#x3D;\epsilon \frac{\parallel f\parallel}{\parallel b\parallel}$</p>
<p>我们就发现，$x$的相对误差差不多是$A,b$的相对误差的$\kappa(A)$倍。于是$\kappa(A)$就衡量了$Ax&#x3D;b$的敏感性。根据前面的范数定义可以写出2-范数下定义的条件数和矩阵奇异值的关系为</p>
<p>$$\kappa(A)&#x3D;\frac{\sigma_{\max}}{\sigma_{\min}}$$</p>
<p>这上面的条件数都是在2-范数下定义的，实际上条件数的定义不依赖于范数，定义也有很多，这里不全列出。但是要记住我们是通过微分引入条件数的。</p>
<p>条件数是衡量矩阵的数值性质的非常好的量，很自然地会想到行列式是不是也是这么样一个量，但是事实上矩阵的行列式和线性系统的解的数值性质关系并不大。</p>
<p>最后，有了条件数，我们就可以用它来较精确地估计线性系统解的偏移量。</p>
<p>$\text{Lemma. }$设方程$Ax &#x3D; b, (A+\Delta A)y&#x3D;b+\Delta b$，且$\parallel \Delta A\parallel\le \epsilon\parallel A\parallel, \parallel \Delta b\parallel\le \epsilon\parallel b\parallel$，则有</p>
<p>$$\frac{\parallel y\parallel}{\parallel x\parallel}\le \frac{1+\epsilon\kappa(A)}{1-\epsilon\kappa(A)}$$</p>
<p>对微扰后的方程左乘$A^{-1}$然后运用条件数的定义和范数性质放缩可得。</p>
<p>$\text{Thm. }$ 如果引理中条件满足，那么</p>
<p>$$\frac{\parallel y - x\parallel}{\parallel x\parallel}\le \frac{2\epsilon \kappa(A)}{1-\epsilon\kappa(A)}$$</p>
<p>证明不难。这个界还行，但还可以更加精细化：</p>
<p>$$\frac{\parallel y-x\parallel_{\infty}}{\parallel x\parallel_{\infty}}\le\frac{2\epsilon}{1-\epsilon \kappa(A)}\parallel |A^{-1}||A|\parallel_{\infty}$$</p>
<p>其中$|A|$表示把|A|的元素全部取绝对值。$\parallel |A^{-1}||A|\parallel_{\infty}$被称为$\text{Skeel}$条件数。</p>
<h2 id="text-2-4-有限精度的计算"><a href="#text-2-4-有限精度的计算" class="headerlink" title="$\text{2.4. 有限精度的计算}$"></a>$\text{2.4. 有限精度的计算}$</h2><p>这个很重要，因为计算机里用的浮点数都是精度有限的。</p>
<p>$\text{IEEE}$标准这种人尽皆知的东西就无需多言了。</p>
<h3 id="text-2-4-1-舍入误差"><a href="#text-2-4-1-舍入误差" class="headerlink" title="$\text{2.4.1. 舍入误差}$"></a>$\text{2.4.1. 舍入误差}$</h3><p>在$\text{IEEE}$标准里，用一定位数的二进制位编码指数，这个位数决定了表示的最低精度，更高的精度就必须舍入，通常采用的是舍入到最近浮点数，也就是所谓的“四舍六入五成双”。</p>
<p>用$\text{round(x)}$表示$x$舍入后的结果，容易发现，如果我们使用$e$位编码指数，那么就有</p>
<p>$$\frac{|\text{round}(x)-x|}{|x|}\le 2^{-e-1}$$</p>
<p>如果考虑到这个层次的细节，那也太过于底层了。计算机按照$\text{IEEE}$标准实现的浮点运算还是值得相信的，为了方便这个层面上的表示，用$\text{fl}(x)$表示$x$作为一个浮点数的存储或者计算。</p>
<p>于是我们就知道$\text{fl}(x)&#x3D;x(1+\delta),|\delta|&lt;2^{-e-1}$</p>
<p>$2^{-e-1}$在书中被记作$u$，对单精度浮点来说差不多是$10^{-7}$，对双精度浮点来说差不多是$10^{-16}$，可以发现如果把这两种浮点数用的编码位带进去，的确是差不多的数量级。</p>
<h3 id="text-2-4-2-浮点数注意事项"><a href="#text-2-4-2-浮点数注意事项" class="headerlink" title="$\text{2.4.2. 浮点数注意事项}$"></a>$\text{2.4.2. 浮点数注意事项}$</h3><h4 id="计算顺序很重要"><a href="#计算顺序很重要" class="headerlink" title="计算顺序很重要"></a>计算顺序很重要</h4><p>这是计算机内容，神书csapp强调过这个事情，无需多言。</p>
<h4 id="逼近精度小不一定是真的小"><a href="#逼近精度小不一定是真的小" class="headerlink" title="逼近精度小不一定是真的小"></a>逼近精度小不一定是真的小</h4><p>例如，如果我们用一阶差分算$\sin x$的数值导数，取步长$h&#x3D;\sqrt{u}$能得到近似最小的误差。</p>
<p>更细节地说一下这个事情，我们如果试图用一阶差分也就是<br>$d&#x3D;\frac{\sin(x+h)-\sin x}{h}$来近似计算导数。假设$\sin$的计算没有误差，那么由数值分析知识（其实就是一个泰勒展开），我们有$|d - \cos x|\sim O(h) $</p>
<p>事实上，正弦函数的数值计算本身也有误差，这是我们无法改变的，我们除以$h$的操作把这个误差放大了$\frac{1}{h}$倍，这意味着$h$绝非取得越小越好，因此实际上我们取$h&#x3D;\sqrt{u}$才能近似地最小化此误差。</p>
<h3 id="text-2-4-3-应用：存储矩阵"><a href="#text-2-4-3-应用：存储矩阵" class="headerlink" title="$\text{2.4.3. 应用：存储矩阵}$"></a>$\text{2.4.3. 应用：存储矩阵}$</h3><p>很容易就能知道，如果把一个矩阵$A$存在计算机里，会有</p>
<p>$$|\text{fl}(A)-A|\le u|A|$$</p>
<p>$$\parallel \text{fl}(A)-A\parallel_1 \le u\parallel A\parallel_1$$</p>
<p>这边很多结论就不细说了，基本上都是一个放缩就能放出来的事情。大部分结论这里会跳过，后面需要用到的时候直接给出结果，不给出证明。</p>
<p>但是有个结论还是在这里提一嘴。</p>
<p>$\text{Lemma. }$ 如果$(1+\alpha)&#x3D;\prod\limits_{k&#x3D;1}^n (1+\alpha_k)$且$|\alpha_k|\le u$且$nu\le 0.01$，那么$|\alpha|\le 1.01nu$</p>
<p>这个结果还是比较恐怖的，它表明如果两个向量的夹角比较接近垂直的话，向量点积的相对误差可能会很大。</p>
<h3 id="text-2-4-4-前向和后向误差分析"><a href="#text-2-4-4-前向和后向误差分析" class="headerlink" title="$\text{2.4.4. 前向和后向误差分析}$"></a>$\text{2.4.4. 前向和后向误差分析}$</h3><p>舍入误差拿来计算相对误差时，既可以是和实际计算结果作比，也可以是和输入数据作比。前者就是前向误差分析，后者就是后向误差分析。</p>
<p>原书在这里还分析了一下$\text{Strassen}$矩阵乘法，略去。</p>
<h3 id="text-2-4-5-分析理想的解方程组"><a href="#text-2-4-5-分析理想的解方程组" class="headerlink" title="$\text{2.4.5. 分析理想的解方程组}$"></a>$\text{2.4.5. 分析理想的解方程组}$</h3><p>我们重新回到数值线性代数的一个重要课题（也是下一个课题）：解方程组$Ax&#x3D;b$.</p>
<p>假设我们解出来的解是$\hat{x}$，那么它满足</p>
<p>$$(A+E)\hat{x} &#x3D; b+e$$</p>
<p>这里的$E$不是单位矩阵，而是误差矩阵。有$\parallel E\parallel_{\infty}\le u\parallel A\parallel_{\infty},\parallel e\parallel_{\infty}\le u\parallel b\parallel_{\infty}$ 并且$\text{fl}(b)&#x3D;b+e,\text{fl}(A)&#x3D;A+E$</p>
<p>假设$u\kappa_{\infty}(A)\le \frac{1}{2}$，那么利用前面在矩阵条件数那里得到的结果，我们就知道</p>
<p>$$\frac{\parallel x-\hat{x}\parallel_{\infty}}{\parallel x\parallel_{\infty}}\le 4u\kappa_{\infty}(A)$$</p>
<h1 id="text-Fin"><a href="#text-Fin" class="headerlink" title="$\text{Fin.}$"></a>$\text{Fin.}$</h1>
    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Numerical-Method/" rel="tag"># Numerical Method</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/09/13/CSE-272-Hw/" rel="prev" title="UCSD CSE272-Advanced Image Synthesis-Homework">
                  <i class="fa fa-chevron-left"></i> UCSD CSE272-Advanced Image Synthesis-Homework
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/11/05/Hello-My-New-Blog/" rel="next" title="Hello, "World"!">
                  Hello, "World"! <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">CLV</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  





  





</body>
</html>
